Понимание, как работает HTML, является ключом к успешному web-парсингу. Когда мы говорим о парсинге, мы имеем в виду процесс извлечения данных из веб-страницы. Однако перед тем, как приступить к этому, нам необходимо "приготовить суп". А что это значит в контексте парсинга? Это процесс передачи HTML кода в конструктор `BeautifulSoup`.

#### **Передача файла с разметкой HTML**

Вам может потребоваться загрузить HTML документ, чтобы анализировать его локально. Это может быть полезно, если у вас есть статический HTML документ или когда вы сталкиваетесь с проблемами доступа к определенному веб-сайту.

[Ссылка](https://parsinger.ru/downloads/cooking_soup/index.zip) на используемый в коде файл.

```
from bs4 import BeautifulSoup
import requests
import lxml

# Пример 1. Передача файла HTML напрямую без использования менеджера контекста
file = open('index.html', encoding='utf-8')
soup = BeautifulSoup(file, 'lxml')
file.close()
print("Анализ файла без использования менеджера контекста:\n", soup)

# Пример 2. Передача файла HTML с использованием менеджера контекста
with open('index.html', 'r', encoding='utf-8') as file:
    soup2 = BeautifulSoup(file, 'lxml')
    print("Анализ файла с использованием менеджера контекста:\n", soup2)
```

Метод с менеджером контекста предпочтительнее, потому что он автоматически заботится о закрытии файла после его использования.

Когда мы парсим веб-сайты, серверы могут блокировать наш IP-адрес из-за слишком многих запросов. Для избежания этой проблемы, мы можем сначала сохранить HTML-страницу на наш компьютер и затем анализировать ее локально. Это особенно полезно, если сервер очень строгий и блокирует нас часто. Сохранение страницы и анализ на компьютере помогает избежать блокировок.

Давайте разберем эту строку:

```
soup = BeautifulSoup(file, 'lxml')

# file: Файловый объект на уровне Python (файловый дескриптор), предоставляющий более 
удобный и высокоуровневый интерфейс для работы с файлом.
# parser: str  # Название парсера (строка)
```

Эта строка используется для создания экземпляра класса BeautifulSoup, который является частью библиотеки BeautifulSoup, предназначенной для парсинга HTML и XML документов.

1. `file`: В Python, когда вы открываете файл с помощью функции `open()`, возвращается файловый объект, который иногда называют "файловым дескриптором" в более общем смысле. Этот объект предоставляет методы для чтения, записи и управления файлом на более высоком уровне.
2. `'[lxml](https://stepik.org/lesson/631856/step/1?unit=627882)'`: Этот параметр представляет собой название парсера, который будет использоваться для анализа HTML или XML кода в файле. `'lxml'` - это один из популярных парсеров, доступных для использования с BeautifulSoup. Он быстрый и эффективный в обработке даже больших файлов.

####  Передаём объект response.text

Для веб-парсинга в реальном времени, когда вы хотите извлечь данные прямо из веб-сайта, используется следующий подход:

```python
from bs4 import BeautifulSoup
import requests
import lxml

# Пример 3. Передача объекта response прямо из запроса
response = requests.get(url='http://parsinger.ru/html/watch/1/1_1.html')
soup = BeautifulSoup(response.text, 'lxml')

print(soup)
```

Этот пример используется чаще всего.  В этом примере мы совершили `.get` запрос, затем передали результат запроса в конструктор **BeautifulSoup**. Обратите внимание на метод `.text`, который мы применили к объекту `response`. Конструктор **BeautifulSoup** умеет работать только с HTML, именно поэтому мы преобразуем объект response в текст.  Если этого не сделать, мы получим ошибку `TypeError: object of type 'Response' has no len()` , об этом важно знать.

_Если у вас во время запроса к данной странице возникли проблемы с кодировкой,  и вы видите нечто подобное `<title>Ð£ÑÐ¸Ð¼ÑÑ Ð¿Ð°ÑÑÐ¸ÑÑ</title>` , необходимо применить кодировку к response._

```
response.encoding = 'utf-8'
```

```
from bs4 import BeautifulSoup
import requests
import lxml

# Пример 3. Передача объекта response прямо из запроса
response = requests.get(url='http://parsinger.ru/html/watch/1/1_1.html')
response.encoding= 'utf-8'
soup = BeautifulSoup(response.text, 'lxml')

print(soup)
```