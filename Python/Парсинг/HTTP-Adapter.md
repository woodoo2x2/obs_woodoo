

`HTTPAdapter` - это компонент [[Модуль requests|библиотеки requests]], который позволяет управлять конфигурацией соединения с сервером. Он предлагает возможности, такие как управление пулом соединений и повторные попытки запросов, что может быть крайне полезным в сетевых приложениях.

Синтаксис:

```python
# Создание адаптера с пользовательской конфигурацией

adapter = HTTPAdapter(
    pool_connections=10,         # Количество соединений в пуле
    pool_maxsize=20,             # Максимальное количество соединений в пуле
    max_retries=5,               # Стратегия повторных попыток
    pool_block=True              # Блокировать или нет, когда пул соединений полон
)
```

#### Параметры конструктора `HTTPAdapter:`

- **`pool_connections`**:
    
    - Этот параметр определяет максимальное количество пулов соединений к различным хостам. Представьте это, как максимальное количество парковок по разным адресам, к которым вы получаете допуск.
- **`pool_maxsize`**:
    
    - Это максимальное количество соединений, которое может быть установлено в пуле. Если вы представите пул соединений как парковку, то `pool_maxsize` это количество мест на этой парковке. Если все места заняты, новые машины (соединения) должны подождать, пока не освободится место.
- **`max_retries`**:
    
    - Количество попыток, которые `HTTPAdapter` сделает для отправки вашего запроса, если возникнут какие-то проблемы (например, временные ошибки сети). Если с первого раза запрос не прошел, он попробует снова и снова, пока не достигнет этого лимита.
- **`pool_block`**:
    
    - Если этот параметр установлен в `True`, то когда все соединения в пуле заняты, новые запросы будут ждать, пока не освободится место, вместо того чтобы тут же возвращать ошибку. Это как если бы вы подъехали к полной парковке и решили подождать, пока кто-то уедет, вместо того чтобы уехать искать другую парковку.

#### Простой пример использования HTTPAdapter:

```python
import requests
from requests.adapters import HTTPAdapter

# Создаем сессию
session = requests.Session()

# Создаем адаптер с конфигурацией по умолчанию
adapter = HTTPAdapter(pool_connections=10, pool_maxsize=20)

# Монтируем адаптер для HTTP и HTTPS
session.mount('http://', adapter)
session.mount('https://', adapter)

# Теперь можно делать запросы через эту сессию
response = session.get('https://httpbin.org/get')
print(response.status_code)  # 200
```

- **Создание сессии**:
    
    - `session = requests.Session()`: Эта строка создает новый объект сессии, который позволяет выполнять HTTP-запросы с определенной конфигурацией.
- **Создание адаптера**:
    
    - `adapter = HTTPAdapter(pool_connections=10, pool_maxsize=20)`: Здесь создается объект `HTTPAdapter` с определенными параметрами для управления пулами соединений. `pool_connections` указывает максимальное количество соединений, которые могут быть установлены в одно и то же время, а `pool_maxsize` определяет максимальное количество соединений в пуле.
- **Монтирование адаптера**:
    
    - `session.mount('http://', adapter)` и `session.mount('https://', adapter)`: Эти строки "*****монтируют" созданный адаптер к HTTP и HTTPS протоколам соответственно в рамках созданной сессии. Это означает, что настройки адаптера будут применяться к каждому запросу, выполняемому через эту сессию, независимо от того, использует ли запрос протокол HTTP или HTTPS.

***Аналогия с монтированием.**

Представьте, что у вас есть набор инструментов для ремонта велосипеда. Если у вас всего один велосипед, вы можете держать все инструменты в одной коробке. Но если у вас есть и горный велосипед, и шоссейный велосипед, возможно, вы захотите организовать инструменты так, чтобы было легче найти нужный инструмент для конкретного велосипеда.

В данном случае, "монтирование адаптера" похоже на то, как если бы вы создали две отдельные коробки для инструментов — одну для горного велосипеда и одну для шоссейного. Каждая коробка представляет собой "адаптер", а тип велосипеда — это "протокол" (HTTP или HTTPS).

**Создание ящиков для инструментов**:

```
adapter = HTTPAdapter(pool_connections=10, pool_maxsize=20)
```

Мы создаёте специальный ящик (`adapter`) для инструментов с определёнными характеристиками.

**Размещение инструментов в ящиках**:

```
session.mount('http://', adapter)
session.mount('https://', adapter)
```

Мы говорим: "_Для всех работ с протоколами HTTP и HTTPS используй этот специальный ящик_ (`adapter`)". Это как если бы вы разложили инструменты по ящикам в зависимости от того, для каких задач они предназначены.

**Использование инструментов из ящика**:

```
response = session.get('https://httpbin.org/get')
```

Вы берёте инструменты из специализированного ящика (`adapter`), чтобы выполнить конкретную задачу — отправить HTTP-запрос.

Представьте себе сценарий: у вас есть веб-сайт, который вы хотите скрапить, и у вас есть большой список прокси-серверов, но качество их работы нестабильно, и они могут перестать работать в любой момент. Это может стать проблемой, особенно если вам нужно собрать большое количество данных в короткие сроки. В такой ситуации наш код приходит на помощь!

С помощью `HTTPAdapter`, мы можем настроить свою сессию так, чтобы автоматически переключаться на другой прокси, если текущий прокси не отвечает. Это делает процесс скрапинга более устойчивым к временным сбоям сети и позволяет продолжать сбор данных даже в условиях неидеальной сетевой среды.

Для запуска следующего примера, вам понадобится несколько рабочих прокси, найти рабочие можно [тут](https://best-proxies.ru/proxylist/free/), [тут](https://hidemy.io/ru/proxy-list/) и [тут](https://spys.one/), или купите приватные прокси [тут](https://proxy6.net/?r=408871), которыми я сам пользуюсь.

```python
import requests
from requests.adapters import HTTPAdapter

# Список прокси
proxies_list = [
    {"http": "http://10.10.1.11:3128", "https": "socks5://10.10.10.11:3128"},
    {"http": "socks5://10.10.10.159:8000", "https": "socks5://10.10.10.159:8000"},
        #...
    {"http": "socks5://10.10.10.216:8000", "https": "socks5://10.10.10.216:8000"},
]
# Создание сессии
session = requests.Session()

def make_request(proxy):
    adapter = HTTPAdapter()
    session.mount('http://', adapter)
    session.mount('https://', adapter)

    try:
        response = session.get('https://httpbin.org/get', proxies=proxy, timeout=5)
        print(f'Успех с прокси {proxy}: {response.status_code}')
    except requests.exceptions.RequestException as e:
        print(f'Не удалось использовать прокси {proxy}: {str(e)}')
        return False   # Возврат False при неудачной попытке
    return True        # Возврат True при успешной попытке

# Перебор прокси и запросов
proxy_index = 0
for i in range(5):
    success = make_request(proxies_list[proxy_index])
    if not success:
        proxy_index = (proxy_index + 1) % len(proxies_list)       # Переход к следующему прокси
        success = make_request(proxies_list[proxy_index])         # Повторный запрос с новым прокси

# Закрытие сессии
session.close()
```

Вывод:

```
Не удалось использовать прокси {'http': 'http://10.10.1.11:3128', 'https': 'socks5://10.10.1.11:3128'}: SOCKSHTTPSConnectionPool(host='httpbin.org', port=443): Max retries exceeded with url: /get (Caused by ConnectTimeoutError(<urllib3.contrib.socks.SOCKSHTTPSConnection object at 0x000001D9625A1790>, 'Connection to httpbin.org timed out. (connect timeout=5)'))
Успех с прокси {'http': 'socks5://10.10.10.159:8000', 'https': 'socks5://10.10.10.159:8000'}: 200
Успех с прокси {'http': 'socks5://10.10.10.159:8000', 'https': 'socks5://10.10.10.159:8000'}: 200
Успех с прокси {'http': 'socks5://10.10.10.159:8000', 'https': 'socks5://10.10.10.159:8000'}: 200
Успех с прокси {'http': 'socks5://10.10.10.159:8000', 'https': 'socks5://10.10.10.159:8000'}: 200
Успех с прокси {'http': 'socks5://10.10.10.159:8000', 'https': 'socks5://10.10.10.159:8000'}: 200
```

В нашем коде, функция `make_request` пытается отправить запрос через текущий прокси. Если запрос не удается, код автоматически переключается на следующий прокси в списке и повторяет запрос. Этот процесс продолжается, пока запрос не выполнится успешно или пока не будут перебраны все прокси в списке.

Такой подход обеспечивает не только повышенную надежность и отказоустойчивость нашего процесса скрапинга, но и упрощает управление множеством прокси, делая код более чистым и легко читаемым.