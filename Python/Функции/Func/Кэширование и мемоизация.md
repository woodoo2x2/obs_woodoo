## Кэширование и мемоизация

Кэширование – это способ оптимизации хранения данных, при котором операции с данными производятся эффективнее.

[[Мемоизация]] — это разновидность кэширования. Обычно под кэшированием понимают довольно широкий набор способов сохранения чего-либо для последующего использования. Мемоизация же означает кэширование возвращаемых значений функций.

Вот некоторые соображения, касающиеся использования мемоизации:

- для того чтобы функцию можно было подвергнуть мемоизации, она должна быть чистой (см. примечание 7)
- мемоизация — это компромисс между производительностью и потреблением памяти
- мемоизация хороша для функций, имеющих сравнительно небольшой диапазон входных значений, что позволяет достаточно часто, при повторных вызовах функций, задействовать значения, найденные ранее, не тратя на хранение данных слишком много памяти
- лучше всего функции с мемоизацией показывают себя там, где выполняются сложные, ресурсоёмкие вычисления

Мы уже сталкивались с мемоизацией в рамках [[Решение задач на рекурсию]] по изучению рекурсии.

Приведенный ниже код:

```python
def fib(n):
    ​cache = {1: 1, 2: 1}
    def fib_rec(n):
        result = cache.get(n)
        if result is None:
            result = fib_rec(n - 2) + fib_rec(n - 1)
            cache[n] = result
        return result
    return fib_rec(n)
```

демонстрирует применение мемоизации к функции вычисления чисел Фибоначчи. При такой реализации функции `fib()` сначала происходит проверка на наличие уже вычисленного элемента, и если он находится, то сразу возвращается его значение.

Несложно написать и декоратор общего типа, мемоизирующий любую чистую функцию:

```python
import functools

def cached(func):
    cache = {}

    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        key = args + tuple(kwargs.items())
        result = cache.get(key)
        if result is None:
            result = func(*args, **kwargs)
            cache[key] = result
        return result
    return wrapper
```

В этой простой реализации мемоизации есть очевидная проблема: содержимое словаря `cache` будет неограниченно расти при каждом вызове декорируемой функции с новыми аргументами.

Для решения такого рода проблемы существуют различные стратегии кэширования.

## Стратегии кэширования

Существует несколько различных стратегий, которые можно использовать для удаления элементов из кэша и предотвращения превышения его максимального размера. Пять самых популярных перечислены в таблице ниже.

|**Стратегия**|**Какую запись удаляем**|**Эти записи чаще других используются повторно**|
|---|---|---|
|First-In, First-Out (FIFO)|самую старую|новые|
|Last-In, First-Out (LIFO)|самую недавнюю|старые|
|Least Recently Used (LRU)|которая использовалась наиболее давно|недавно прочитанные|
|Most Recently Used (MRU)|которая использовалась последней|прочитанные первыми|
|Least Frequently Used (LFU)|которая использовалась наиболее редко|которые использовались часто|

Стратегия LRU представляет собой метод управления кэшем, в котором данные, которые дольше всего не использовались, считаются наименее ценными, и они удаляются из кэша в первую очередь при необходимости освободить место для новых данных. Кэш, реализованный посредством стратегии LRU, упорядочивает элементы в порядке их использования. Каждый раз, когда мы обращаемся к записи, алгоритм LRU перемещает ее в верхнюю часть кэша. Таким образом, алгоритм может быстро определить запись, которая дольше всех не использовалась, проверив конец списка.



Кэширование – один из подходов, который при правильном использовании значительно ускоряет работу и снижает нагрузку на вычислительные ресурсы. Кэширование очень часто используется в реальных проектах.

Будьте осторожны с мемоизацией функций, которые принимают изменяемые типы данных в качестве аргументов. Встроенный декоратор [[Декоратор lru_cache]] не позволяет работать с нехэшируемыми объектами, так как за кулисами использует словарь.

 Все алгоритмы кэширования доступны в модуле `cachetools` по [ссылке](https://github.com/tkem/cachetools/).

 В Python 3.9 появился декоратор `cache`, который работает так же, как и `lru_cache`, но без ограничений на размер кэша. По сути, применение декоратора `cache` равнозначно применению декоратору `lru_cache(maxsize=None)`. Такой декоратор работает быстрее чем `lru_cache` c заданным `maxsize`, но потребляет больше памяти.

 